{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designing-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bandit import Bandit\n",
    "from context_engineering_functions import *\n",
    "from logging_policy import LoggingPolicy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from evaluation import train_value_estimator, evaluate\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-remedy",
   "metadata": {},
   "source": [
    "Need to take a Bandit object - which contains a policy to evaluate, and also a Logging Policy Object.\n",
    "We estimate the value using the Direct Method, where we fit a ridge regression w/ importance weights onto the reward function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "outer-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = './csgo_clean/'\n",
    "map_pick_context, vetoes_only_context = create_basic_pick_veto_triples(data_directory) # Not important, but loaded vetoes too\n",
    "map_pick_context_train, map_pick_context_test  = train_test_split(map_pick_context,test_size=.2,train_size=.8,shuffle=False)\n",
    "\n",
    "cols = [col for col in map_pick_context if col.endswith('is_available')]\n",
    "X_train = map_pick_context_train[cols].values\n",
    "A_train = map_pick_context_train['X_Action'].values\n",
    "Y_train = map_pick_context_train['Y_reward'].values\n",
    "\n",
    "X_test = map_pick_context_test[cols].values\n",
    "A_test = map_pick_context_test['X_Action'].values\n",
    "Y_test = map_pick_context_test['Y_reward'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "amended-presence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for random row: \n",
      "[[0.2 0.2 0.  0.2 0.2 0.2 0. ]]\n"
     ]
    }
   ],
   "source": [
    "n_arms = 7\n",
    "\n",
    "# randomly chosen by dice roll\n",
    "n = 4569\n",
    "# n = np.random.choice(context.index)\n",
    "\n",
    "bandit = Bandit(X_train.shape[1], n_arms, step_size=0.01)\n",
    "\n",
    "print('Probabilities for random row: ')\n",
    "print(bandit.predict_proba(X_train[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sticky-airplane",
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = LoggingPolicy(map_pick_context_train,map_pick_context_train['X_Action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conservative-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: multiple epochs, parameter tuning\n",
    "for i in range(X_train.shape[0]):\n",
    "    bandit.update_theta(X_train[i].reshape(1, -1), A_train[i], Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "medium-groove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16526486 0.2547316  0.         0.26307424 0.1534473  0.163482\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(bandit.predict_proba(X_train[n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-practice",
   "metadata": {},
   "source": [
    "### Multi-epoch loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noticed-pleasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: multiple epochs, parameter tuning\n",
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(X_train.shape[0]):\n",
    "        bandit.update_theta(X_train[i].reshape(1, -1), A_train[i], Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mathematical-aspect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.15566783 0.25676085 0.         0.27968643 0.1492302  0.15865469\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(bandit.predict_proba(X_train[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sexual-mambo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities for random row after training: \n",
      "[[0.15566783 0.25676085 0.         0.27968643 0.1492302  0.15865469\n",
      "  0.        ]]\n",
      "Selected action: \n",
      "[3]\n",
      "Actual action and reward for random row: \n",
      "Action: 4, reward: 0\n"
     ]
    }
   ],
   "source": [
    "print('Probabilities for random row after training: ')\n",
    "print(bandit.predict_proba(X_train[n]))\n",
    "print('Selected action: ')\n",
    "print(bandit.predict(X_train[n]))\n",
    "\n",
    "print('Actual action and reward for random row: ')\n",
    "print(f'Action: {A_train[n]}, reward: {Y_train[n]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-working",
   "metadata": {},
   "outputs": [],
   "source": [
    "action_to_model_dict = train_value_estimator(X_train, map_pick_context_train, A_train, Y_train, log_policy=lp, target_bandit=bandit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ruled-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniform policy: untrained bandit\n",
    "untrained_bandit = Bandit(X_train.shape[1], n_arms, step_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "planned-wagon",
   "metadata": {},
   "source": [
    "MHS: Nothing important different down here, except I added the Test data section too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-wright",
   "metadata": {},
   "source": [
    "### Eval on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "twelve-bridal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Bandit:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.5495714285714286,\n",
       " 'IW': 1.3000251226930468,\n",
       " 'SN_IW': 0.5582780985246645,\n",
       " 'Direct_Method_IW': 0.5583079306013885}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trained Bandit:\")\n",
    "evaluate(X_train, map_pick_context_train, A_train, Y_train, \\\n",
    "         log_policy=lp, target_bandit=bandit, action_to_model_dict=action_to_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "preceding-semiconductor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Policy:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.5495714285714286,\n",
       " 'IW': 1.254442289045975,\n",
       " 'SN_IW': 0.5558585769907851,\n",
       " 'Direct_Method_IW': 0.5559663867915816}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uniform Policy:\")\n",
    "evaluate(X_train, map_pick_context_train, A_train, Y_train, \\\n",
    "         log_policy=lp, target_bandit=untrained_bandit,action_to_model_dict=action_to_model_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-anxiety",
   "metadata": {},
   "source": [
    "### Eval on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "exempt-style",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Bandit:\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.5362649914334666,\n",
       " 'IW': 1.1751889281300871,\n",
       " 'SN_IW': 0.5701120532080091,\n",
       " 'Direct_Method_IW': 0.5596151524302753}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trained Bandit:\")\n",
    "evaluate(X_test, map_pick_context_test, A_test, Y_test, \\\n",
    "         log_policy=lp, target_bandit=bandit, action_to_model_dict=action_to_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acute-sydney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Policy:\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 549 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n",
      "Team ID 18 not seen during training. Using default policy.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean': 0.5362649914334666,\n",
       " 'IW': 1.155900524260706,\n",
       " 'SN_IW': 0.5674112357209264,\n",
       " 'Direct_Method_IW': 0.5570846554003637}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Uniform Policy:\")\n",
    "evaluate(X_test, map_pick_context_test, A_test, Y_test, \\\n",
    "         log_policy=lp, target_bandit=untrained_bandit, action_to_model_dict=action_to_model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-machinery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
